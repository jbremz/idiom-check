{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IdiomCheck - Language Detection\n",
    "\n",
    "Here I detail my attempts to create a language classifier trained on the [European Parliament Proceedings Parallel Corpus](http://www.statmt.org/europarl/) and tested using [this](https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/language-detection/europarl-test.zip) dataset.\n",
    "\n",
    "I use three approaches:\n",
    "- [N-gram frequency distribution comparison](#rank)\n",
    "- [Markov chain MLE](#markov)\n",
    "- [LSTM-based neural network](#lstm)\n",
    "\n",
    "The best-performing model was the Markov chain MLE which produced a classification accuracy of **99.77%**.\n",
    "\n",
    "[Model Performance Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_cleaner(sample):\n",
    "    '''\n",
    "    Takes a string and removes unwanted characters/formatting\n",
    "    '''\n",
    "    \n",
    "    sample = re.sub(r'[^\\u0000-\\u0800]', '', sample) # select only the first 2048 UTF-8 characters\n",
    "    sample = re.sub(r'\\([^)]*\\)', ' ', sample) # rm characters within brackets\n",
    "    sample = re.sub('<[^>]+>', '', sample) # rm characters within <>\n",
    "    sample = re.sub(r'\\d+', '', sample) # rm one or more digits\n",
    "    sample = sample.replace('\\n', ' ') # rm line delimiters\n",
    "    sample = re.sub(r'/[^\\w\\s]/gi', '', sample)\n",
    "    sample = re.sub(r'\\W+', ' ', sample) # rm non-word characters\n",
    "    sample = re.sub(\"'\", '', sample) # rm single quotes\n",
    "    sample = sample.lower() # make lowercase\n",
    "    sample = re.sub(r'^\\s','', sample) # rm space at start\n",
    "    sample = re.sub(r'\\s$','', sample) # rm space at end\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(file_list, clean=True):\n",
    "    '''\n",
    "    Inputs:\n",
    "    file_list - the list of paths of the text files to create the corpus\n",
    "    clean - bool - if True: applies string_cleaner() to the strings\n",
    "    \n",
    "    Returns:\n",
    "    A list of strings containing the corpus\n",
    "    '''\n",
    "    corpus = []\n",
    "\n",
    "    for file_path in file_list:\n",
    "        with open(file_path) as f_input:\n",
    "            sample = f_input.read()[:20000] # take first 20000 characters of each file for sake of computation time / memory constraints\n",
    "            if clean:\n",
    "                sample = string_cleaner(sample)\n",
    "            if len(sample) > 0:\n",
    "                corpus.append(sample)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<CHAPTER ID=\"006\">\\nИзбор на квестори на Европейския парламент (срок за депозиране на кандидатури): вж. протокола\\n<P>\\n(Die Sitzung wird um 15.25 Uhr unterbrochen und um 18.00 Uhr wiederaufgenommen).\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), \"txt\", \"bg\",\"*.txt\"))\n",
    "the_corpus = corpus(file_list[:50], clean=False)\n",
    "the_corpus[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Bulgarian sample above contains a number of characters and formatting we wish to remove (including some German in brackets). Have altered `string_cleaner()` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'избор на квестори на европейския парламент вж протокола'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_corpus = corpus(file_list[:50])\n",
    "the_corpus[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they've been removed, great. It has also removed all other text in brackets but this will be in a minority of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), \"txt\", \"cs\",\"*.txt\"))\n",
    "the_corpus = corpus(file_list[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schválení zápisu z předchozího zasedání viz zápis\n",
      "členství ve výborech a delegacích viz zápis\n",
      "předložení dokumentů viz zápis\n"
     ]
    }
   ],
   "source": [
    "print(the_corpus[0])\n",
    "print(the_corpus[1])\n",
    "print(the_corpus[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the early files contain the same ending (`viz zápis`) which we should strip as these will effect the models. Luckily each language has the same phrase after the colon in the same corresponding file. My guess is that this doesn't affect the overall statistics though, given that it'll be lost amongst large text files. We can always come back and alter this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "The test data comes as a .tsv file with the first column representing the language and the second column containing the string of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('europarl-test.txt', sep='\\t', header=None, names=['language', 'string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>Европа 2020 не трябва да стартира нов конкурен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>(CS) Най-голямата несправедливост на сегашната...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>(DE) Г-жо председател, г-н член на Комисията, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>(DE) Г-н председател, бих искал да започна с к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>(DE) Г-н председател, въпросът за правата на ч...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                             string\n",
       "0       bg  Европа 2020 не трябва да стартира нов конкурен...\n",
       "1       bg  (CS) Най-голямата несправедливост на сегашната...\n",
       "2       bg  (DE) Г-жо председател, г-н член на Комисията, ...\n",
       "3       bg  (DE) Г-н председател, бих искал да започна с к...\n",
       "4       bg  (DE) Г-н председател, въпросът за правата на ч..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to strip the '(CS)','(DE)' etc. As well as all the non-alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>европа не трябва да стартира нов конкурентен м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>най голямата несправедливост на сегашната обща...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg</td>\n",
       "      <td>г жо председател г н член на комисията по прин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg</td>\n",
       "      <td>г н председател бих искал да започна с комента...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bg</td>\n",
       "      <td>г н председател въпросът за правата на човека ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                             string\n",
       "0       bg  европа не трябва да стартира нов конкурентен м...\n",
       "1       bg  най голямата несправедливост на сегашната обща...\n",
       "2       bg  г жо председател г н член на комисията по прин...\n",
       "3       bg  г н председател бих искал да започна с комента...\n",
       "4       bg  г н председател въпросът за правата на човека ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['string'] = test['string'].apply(lambda x: string_cleaner(x))\n",
    "test = test[test['string'].apply(len) != 0] # remove empty strings\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to remove the rows with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20762, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a test dataset of 20828 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu',\n",
       "       'it', 'lt', 'lv', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = next(os.walk('./txt'))[1]\n",
    "np.array(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu',\n",
       "       'it', 'lt', 'lv', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test.language.unique()).issubset(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore all of the languages in the test dataset are in the training dataset, this is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median string length: 131 characters\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [len(x) for x in test['string']]\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Number of Characters')\n",
    "plt.hist(lengths,40, range=(0,1000))\n",
    "print('Median string length: %.0f characters' % np.median(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rank'></a>\n",
    "## N-gram Rank Similarity Method\n",
    "\n",
    "I'm going to first try a [traditional method](http://odur.let.rug.nl/vannoord/TextCat/textcat.pdf) of ranked n-gram frequency similarity. I'll carry this out at the character level, since some of the test samples may be very short - we want to create a meaningful rank distribution.\n",
    "\n",
    "The authors in the linked paper use a simple rank similarity metric of the average distance between characters in the two ranks being compared. When comparing multiple languages, the language which produces the _smallest_ value of this metric is deemed the model's best prediction.\n",
    "\n",
    "It is unclear how the authors deal with n-grams which aren't mutually contained in the two ranks being compared. They simply write \"no-match = max\" which I've interpreted as setting no-matches equal to the max distance, which is equal to the length of the rank. The authors also report good classification for rank lengths as short as 200, so I shall use this rank length (perhaps experimenting later on). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sim(a, b):\n",
    "    '''\n",
    "    Takes two ranked arrays of the same shape and returns the average distance between the indices of matching elements\n",
    "    Elements which don't match are given a distance of the length of the array (this will perform poorly on short strings)\n",
    "    '''\n",
    "    c = a[np.where(np.in1d(a,b))[0]]\n",
    "    d = c.reshape((len(c),1))\n",
    "    e = np.abs(np.where(np.in1d(a,b))[0]-np.where(d==b)[1])\n",
    "    no_match_penalty = (len(a)-len(e))*len(a) # TODO: make this condition more rigourous\n",
    "    \n",
    "    return (e.sum() + no_match_penalty)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(corpus, ngram_range=(1,3), rank_length=200):\n",
    "    '''\n",
    "    Inputs:\n",
    "    corpus - a list of strings\n",
    "    ngram_range - the range of ngram lengths to consider (defaults to 1-3)\n",
    "    rank_length - the length of the rank list to return (defaults to 200)\n",
    "    \n",
    "    Retuns:\n",
    "    rank - the array of ngrams ordered by frequency of occurrence in the corpus\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(input='content',ngram_range=(1,3), analyzer='char_wb')\n",
    "    transformed = vectorizer.fit_transform(corpus)\n",
    "    features = vectorizer.get_feature_names()\n",
    "    sums = transformed.sum(axis=0)\n",
    "    \n",
    "    return np.array(features)[np.array(np.argsort(sums[0,:]))[0]][-rank_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the functions on some example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_sl = glob.glob(os.path.join(os.getcwd(), \"txt\", \"sl\",\"*.txt\"))\n",
    "file_list_lv = glob.glob(os.path.join(os.getcwd(), \"txt\", \"lv\",\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slovakian/Latvian similarity score: 138.335\n",
      "Slovakian/Slovakian similarity score: 49.7\n",
      "Latvian/Latvian similarity score: 60.48\n"
     ]
    }
   ],
   "source": [
    "corpus_sl_1 = corpus(file_list_sl[:50])\n",
    "corpus_sl_2 = corpus(file_list_sl[50:100])\n",
    "corpus_lv_1 = corpus(file_list_lv[:50])\n",
    "corpus_lv_2 = corpus(file_list_lv[50:100])\n",
    "\n",
    "rank_sl_1 = rank(corpus_sl_1)\n",
    "rank_sl_2 = rank(corpus_sl_2)\n",
    "rank_lv_1 = rank(corpus_lv_1)\n",
    "rank_lv_2 = rank(corpus_lv_2)\n",
    "\n",
    "print('Slovakian/Latvian similarity score:', rank_sim(rank_sl_1, rank_lv_1))\n",
    "print('Slovakian/Slovakian similarity score:', rank_sim(rank_sl_1, rank_sl_2))\n",
    "print('Latvian/Latvian similarity score:', rank_sim(rank_lv_1, rank_lv_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both languages show similarity to themselves (a low score means a stronger agreement between their ranks), and less similarity between each other. In this simple binary classification, the two languages would have been told apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we will need to classify a given sample of text are the ranked ngrams for each language after analysing the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = {}\n",
    "\n",
    "for language in tqdm(languages):\n",
    "    file_list = glob.glob(os.path.join(os.getcwd(), \"txt\", language,\"*.txt\"))\n",
    "    lang_corpus = corpus(file_list[:500])\n",
    "    lang_rank = rank(lang_corpus, rank_length=100)\n",
    "    ranks[language] = lang_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating N-gram Rank Similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiom_check(lang_sample, ranks, print_scores=False):\n",
    "    '''\n",
    "    Inputs:\n",
    "    lang_sample - the string to be classified\n",
    "    ranks - the dict() containing the language keys and their corresponding ranks\n",
    "    print_scores - bool - if True, the scores for each separate language is printed\n",
    "    \n",
    "    Returns:\n",
    "    The predicted language of lang_sample\n",
    "    '''\n",
    "    scores = {}\n",
    "    \n",
    "    sample_rank = rank([lang_sample])\n",
    "    \n",
    "    for key, rk in ranks.items():\n",
    "        scores[key] = rank_sim(sample_rank, rk)\n",
    "        \n",
    "    if print_scores:\n",
    "        print(scores)\n",
    "\n",
    "    return min(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test.copy()\n",
    "results['pred_lang'] = results['string'].apply(lambda x: idiom_check(x, ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040169540506695\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',(results['language'] == results['pred_lang']).sum()/len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't terrible, but we could do better. We could probably improve this method by training the model on a larger dataset, but given the constraints of my machine, I couldn't do this.\n",
    "\n",
    "Let's produce a confusion matrix from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted    bg   cs    da    de   el    en   es   et    fi    fr   ...     \\\n",
      "Actual                                                              ...      \n",
      "bg          994    3     0     0    0     0    0    0     0     0   ...      \n",
      "cs            2  645    18     3    0    16    1   15    40     6   ...      \n",
      "da            3    0   950     2    0     3    0    1     0     1   ...      \n",
      "de            1    0     7   969    0     0    1    0     0     0   ...      \n",
      "el            1    0     0     0  986     0    0    0     0     0   ...      \n",
      "en            2    0     5     4    0   950    1    0     0    10   ...      \n",
      "es            1    1     1     2    0     2  873    1     0    10   ...      \n",
      "et            3    0    10     3    0     1    0  473   456     1   ...      \n",
      "fi            1    0     2     1    0     0    0    1   987     0   ...      \n",
      "fr            4    0     5     3    0     0   13    0     0   946   ...      \n",
      "hu            5    1   221     6    0     8    5    3    98     8   ...      \n",
      "it            1    0     0     2    0     0   16    0     0     9   ...      \n",
      "lt            2    0    12     4    0     3    5   13    54     5   ...      \n",
      "lv            0    0     4     9    0     2    3    6    20     3   ...      \n",
      "nl            0    0     6    23    0     2    0    0     0     1   ...      \n",
      "pl            5    5     3     9    0    25    2    2     9     0   ...      \n",
      "pt            3    0     0     0    0     1   12    0     0     2   ...      \n",
      "ro            2    3    12     7    0     2   41    0     0   104   ...      \n",
      "sk            1   84    11     4    0     7    6    4    39     5   ...      \n",
      "sl            1    3    37     1    0     8    5    8    33     2   ...      \n",
      "sv            1    0    34     0    0     0    2    1     2     0   ...      \n",
      "__all__    1033  745  1338  1052  986  1030  986  528  1738  1113   ...      \n",
      "\n",
      "Predicted   lt   lv    nl   pl    pt   ro   sk   sl    sv  __all__  \n",
      "Actual                                                              \n",
      "bg           0    0     0    0     0    0    0    0     0      997  \n",
      "cs           1    5    27    1    28    2   58   38    13      993  \n",
      "da           0    0     6    0     1    0    0    0    21      994  \n",
      "de           0    0     9    0     0    0    0    0     6      994  \n",
      "el           0    0     0    0     0    1    0    0     0      988  \n",
      "en           0    0    13    0     2    0    0    0     6      999  \n",
      "es           1    0     0    0    87    0    1    0     0      997  \n",
      "et           1    0    24    0     3    0    0    2     9      994  \n",
      "fi           0    0     0    0     1    0    0    0     2      995  \n",
      "fr           1    0     3    0    11    3    0    0     6      999  \n",
      "hu           0    1   126    0     4    0    1    1   115      998  \n",
      "it           0    0     0    0    36    2    0    0     1      996  \n",
      "lt         814   20     9    0    18    2    0    0    10      995  \n",
      "lv          16  869    13    1     9    1    1    0     9      978  \n",
      "nl           1    1   959    0     2    2    0    0     1      999  \n",
      "pl           1    6    11  819    19    0   15    8     4      999  \n",
      "pt           0    0     0    0   971    0    0    0     0      996  \n",
      "ro           0    1     7    0    75  249    2    0     6      928  \n",
      "sk           7    4    41   10    44    2  437   88    27      929  \n",
      "sl          23   13    46    0    36    7    2  561    13      998  \n",
      "sv           0    0     6    0     0    0    0    0   946      996  \n",
      "__all__    866  920  1300  831  1347  271  517  698  1195    20762  \n",
      "\n",
      "[22 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = ConfusionMatrix(results['language'], results['pred_lang'])\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors seem to come mainly from Estonian, Hungarian, Romanian and Slovakian. Let's try a different method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='markov'></a>\n",
    "## Markov Chain MLE\n",
    "\n",
    "The n-gram approach works fine, but isn't very well suited to short strings which don't contain a large number of unique n-grams. I believe a character-level Markov chain approach could perform better on shorter phrases because it doesn't have this limitation. \n",
    "\n",
    "I aim to treat each string as a first-order Markov chain and then extract the character-level transition matrix for each language. Then I can calculate the $\\log(probability)$ for a particular string to belong to each language and choose the maximally likely option. Something along the lines of [this](https://pdfs.semanticscholar.org/2bf0/8addb83f51befa8b4bc7ed16b54ed34018d0.pdf) I suppose. I have chosen to ignore the initial character probabilities, as their contribution to the final result is likely to be very small. However, this means that what I construct here is not technically a true Markov chain.\n",
    "\n",
    "There don't seem to be any Python packages for markov chains(?!) I will have to code this myself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From - stackoverflow.com/a/43413801\n",
    "\n",
    "def strided_axis0(a, L):\n",
    "    # Store the shape and strides info\n",
    "    shp = a.shape\n",
    "    s  = a.strides\n",
    "\n",
    "    # Compute length of output array along the first axis\n",
    "    nd0 = shp[0]-L+1\n",
    "\n",
    "    # Setup shape and strides for use with np.lib.stride_tricks.as_strided\n",
    "    # and get (n+1) dim output array\n",
    "    shp_in = (nd0,L)+shp[1:]\n",
    "    strd_in = (s[0],) + s\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shp_in, strides=strd_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the transitions as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', 'h'],\n",
       "       ['h', 'i'],\n",
       "       ['i', 's'],\n",
       "       ['s', ' '],\n",
       "       [' ', 'i'],\n",
       "       ['i', 's'],\n",
       "       ['s', ' '],\n",
       "       [' ', 'a'],\n",
       "       ['a', ' '],\n",
       "       [' ', 't']], dtype='<U1')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = \"This is a test\"\n",
    "test_arr = np.array(list(trial))\n",
    "pairs = strided_axis0(test_arr, 2)\n",
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strided_axis0(test_arr, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(strided_axis0(test_arr, 2), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are only 11 unique transitions out of 13 measured transitions - this is how we will build our transition matrix.\n",
    "\n",
    "Our transition matrix could end up being quite large. We already have over 16,000 entries for the 128 characters in US-ASCII, if we extend this to the Greek characters then this could be around 4,000,000 entries.\n",
    "\n",
    "It's probably best to store these as a (vectorised) numpy array. We will now write a function to integer-encode each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_encode(groups, encoder):\n",
    "    '''\n",
    "    Input:\n",
    "    groups - array - groups of characters to be encoded\n",
    "    encoder - a sklearn.preprocessing.LabelEncoder object which has been prefitted to a vocabulary\n",
    "    \n",
    "    Returns:\n",
    "    int_encoded - array - the integer encoded groups\n",
    "    '''\n",
    "    flat_groups = groups.flatten()\n",
    "    try:\n",
    "        int_encoded = encoder.transform(flat_groups).reshape(groups.shape)\n",
    "    except ValueError:\n",
    "        print('Error:',''.join(list(groups[:,1])))\n",
    "    \n",
    "    return int_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to work out a way of dealing with the zero-valued probabilities - these are events that aren't in the training data, but could be seen in the test data. For this it seems we should use some kind of [smoothing](https://pdfs.semanticscholar.org/5b2b/78087e51641a02966d6dcf20b51a5c43ccca.pdf). I should use _absolute discounting_ as it is easy to implement and apparently quite effective (would ideally use _Kneser-Ney smoothing_ but this would be very involved). [Here](http://u.cs.biu.ac.il/~yogo/courses/mt2013/papers/chen-goodman-99.pdf) is a good guide.\n",
    "\n",
    "However, this still seems too time-consuming. It may suffice to add a very small amount of probability to the zero values, we'll see when we test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(trans_mat):\n",
    "    '''\n",
    "    Smooths zero values with a small number << 1 (an altered form of Laplace smoothing)\n",
    "    \n",
    "    TODO: turn this into Kneser-Ney smoothing\n",
    "    \n",
    "    '''\n",
    "    smooth_prob = trans_mat[(trans_mat != 0) & ~np.isnan(trans_mat)].min()/10 # take the minimum probability and choose something smaller than it\n",
    "    trans_mat[trans_mat == 0] = smooth_prob\n",
    "    trans_mat[np.isnan(trans_mat)] = smooth_prob\n",
    "    \n",
    "    return trans_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(text_list, vocab, encoder):\n",
    "    '''\n",
    "    Input:\n",
    "    text_list - list of strings - the texts to analyse\n",
    "    \n",
    "    Returns:\n",
    "    trans_mat - array - the Markovian transition matrix for the text given\n",
    "    vocab - array - an array where the index of each item corresponds to the position in trans_mat: a lookup\n",
    "    '''\n",
    "    count_mat_master = np.zeros((vocab.shape[0],vocab.shape[0])) # intialise the master count matrix with zero counts\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        if len(text) < 2:\n",
    "            continue\n",
    "        text = np.array(list(text)) # prepare text as array of separate characters\n",
    "        pairs = strided_axis0(text, 2) # window characters into consecutive pairs\n",
    "        int_pairs = int_encode(pairs, encoder) # integer encode the characters\n",
    "        unique, counts = np.unique(int_pairs, return_counts=True, axis=0) # count the separate instances of the transitions\n",
    "        count_mat = np.zeros((vocab.shape[0],vocab.shape[0]))\n",
    "        count_mat[unique[:,0],unique[:,1]] = counts # populate the count matrix\n",
    "        count_mat_master += count_mat # add the counts to the master count matrix\n",
    "        \n",
    "    count_mat_master = smooth(count_mat_master)\n",
    "    trans_mat = count_mat_master/count_mat_master.sum(axis=1).reshape(count_mat_master.shape[0],1) # normalise the transition matrix (row stochastic)\n",
    "    \n",
    "    return trans_mat, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(text, TM_list, encoder):\n",
    "    '''\n",
    "    Inputs:\n",
    "    text - string - the sample to be analysed\n",
    "    TM_list - array - the list of transition matrices containing the transition probabilities for the calculation for each langauge\n",
    "    encoder - LabelEncoder() object - the fitted LabelEncoder() object to integer encode the text\n",
    "    \n",
    "    Returns:\n",
    "    log_likelihood - float - the log-likelihood for the string\n",
    "    \n",
    "    '''\n",
    "    text = np.array(list(text))\n",
    "    pairs = strided_axis0(text, 2)\n",
    "    int_pairs = int_encode(pairs, encoder)\n",
    "    prob_lists = np.zeros((TM_list.shape[0], int_pairs.shape[0]))\n",
    "    \n",
    "    for i, TM in enumerate(TM_list):\n",
    "        prob_lists[i] = TM[int_pairs[:,0],int_pairs[:,1]]\n",
    "    \n",
    "    return np.log(prob_lists).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to extract my vocab from the training data, or I could create a sample of every character that's possible to create with two bytes of UTF-8? Let's try using the first $128 + 1920 = 2,048$ characters. We have filtered to these characters in our text preprocessing anyway. This will be a very sparse matrix, but not too large for our means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array([chr(i) for i in range(2048)])\n",
    "encoder = LabelEncoder().fit(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Test\n",
    "\n",
    "Let's test the routines on our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_sl = glob.glob(os.path.join(os.getcwd(), \"txt\", \"sl\",\"*.txt\"))\n",
    "file_list_lv = glob.glob(os.path.join(os.getcwd(), \"txt\", \"lv\",\"*.txt\"))\n",
    "\n",
    "# Produce corpora\n",
    "corpus_sl_1 = corpus(file_list_sl[:50])\n",
    "corpus_sl_2 = corpus(file_list_sl[50:100])\n",
    "corpus_lv_1 = corpus(file_list_lv[:50])\n",
    "corpus_lv_2 = corpus(file_list_lv[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate tranisition matrices\n",
    "TM_list = np.array([transition_matrix(corpus, vocab, encoder)[0] for corpus in [corpus_sl_1, corpus_lv_1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce log-likelihoods\n",
    "log_likes = np.zeros((len(corpus_sl_2),len(TM_list)))\n",
    "for i, sample in enumerate(corpus_sl_2):\n",
    "    log_likes[i,:] = log_like(sample, TM_list, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary detection accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "percentage_accuracy = 100*(np.where(log_likes[:,0] > log_likes[:,1])[0].shape[0] / log_likes.shape[0])\n",
    "print(\"Binary detection accuracy: %d%%\" % percentage_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model does indeed produce a larger log likelihood for the correct language, this is great. Now I need to create transition matrices for all of the languages and evaluate the model on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Markov Chain MLE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'it', 'lt', 'lv', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_list = np.zeros((len(languages), len(vocab), len(vocab)))\n",
    "\n",
    "for i, language in enumerate(tqdm(languages)):\n",
    "    file_list = glob.glob(os.path.join(os.getcwd(), \"txt\", language,\"*.txt\"))\n",
    "    a_corpus = corpus(file_list[:4000]) # take first 4000 files for sake of computation time\n",
    "    TM_list[i] = transition_matrix(a_corpus, vocab, encoder)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the performance on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiom_check_mkv(lang_sample, TM_list, languages, encoder):\n",
    "    '''\n",
    "    Inputs:\n",
    "    lang_sample - the string to be classified\n",
    "    TM_list - array containing the transition matrices for each language\n",
    "    languages - list - list of the two character strings representing each language\n",
    "    encoder - sklearn.preprocessing.LabelEncoder obj - prefitted encoder\n",
    "    \n",
    "    Returns:\n",
    "    The predicted language of lang_sample - string\n",
    "    '''\n",
    "\n",
    "    return languages[np.argmax(log_like(lang_sample, TM_list, encoder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test.copy()\n",
    "results['pred_lang'] = results['string'].apply(lambda x: idiom_check_mkv(x, TM_list, languages, encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9977362489162894\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',(results['language'] == results['pred_lang']).sum()/len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.77% is comparable if not better than the performance [reported in the literature](https://pdfs.semanticscholar.org/2bf0/8addb83f51befa8b4bc7ed16b54ed34018d0.pdf), although we are of course using a different test dataset. I think at this point improvements would have to come either by using a larger sample for the transition matrices, or by improving on the smoothing technique (which is very rudimentary as it stands). Let's look to see where it failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted   bg   cs   da   de   el    en   es   et   fi   fr   ...      lt  \\\n",
      "Actual                                                         ...           \n",
      "bg         997    0    0    0    0     0    0    0    0    0   ...       0   \n",
      "cs           0  985    0    0    0     1    0    0    0    0   ...       0   \n",
      "da           0    0  989    0    0     0    0    0    0    0   ...       0   \n",
      "de           0    0    0  991    0     1    0    0    0    0   ...       0   \n",
      "el           0    0    0    0  988     0    0    0    0    0   ...       0   \n",
      "en           0    1    0    0    0   998    0    0    0    0   ...       0   \n",
      "es           0    0    0    0    0     0  993    0    0    0   ...       0   \n",
      "et           0    0    0    0    0     0    0  993    0    0   ...       0   \n",
      "fi           0    0    0    0    0     0    0    0  994    0   ...       0   \n",
      "fr           0    0    0    1    0     1    1    0    0  993   ...       0   \n",
      "hu           0    0    0    0    0     0    0    0    0    0   ...       0   \n",
      "it           0    0    0    0    0     0    1    0    0    0   ...       0   \n",
      "lt           0    0    0    0    0     0    0    0    0    0   ...     995   \n",
      "lv           0    0    0    0    0     0    0    0    0    0   ...       0   \n",
      "nl           0    0    1    1    0     0    0    0    0    0   ...       0   \n",
      "pl           0    0    0    0    0     1    0    0    0    0   ...       0   \n",
      "pt           0    0    0    0    0     1    0    0    0    0   ...       0   \n",
      "ro           0    0    0    0    0     0    0    0    0    1   ...       0   \n",
      "sk           0    3    0    0    0     0    0    0    0    0   ...       0   \n",
      "sl           0    1    0    0    0     0    1    0    0    0   ...       1   \n",
      "sv           0    0    3    0    0     0    0    0    0    0   ...       0   \n",
      "__all__    997  990  993  993  988  1003  996  993  994  994   ...     996   \n",
      "\n",
      "Predicted   lv    nl   pl    pt   ro   sk   sl    sv  __all__  \n",
      "Actual                                                         \n",
      "bg           0     0    0     0    0    0    0     0      997  \n",
      "cs           0     0    0     0    0    7    0     0      993  \n",
      "da           0     0    0     0    0    0    0     5      994  \n",
      "de           0     2    0     0    0    0    0     0      994  \n",
      "el           0     0    0     0    0    0    0     0      988  \n",
      "en           0     0    0     0    0    0    0     0      999  \n",
      "es           0     0    0     3    0    0    0     0      997  \n",
      "et           0     1    0     0    0    0    0     0      994  \n",
      "fi           0     0    0     0    0    0    0     1      995  \n",
      "fr           0     0    1     1    0    0    0     0      999  \n",
      "hu           0     0    0     0    0    0    0     1      998  \n",
      "it           0     0    0     0    0    0    0     0      996  \n",
      "lt           0     0    0     0    0    0    0     0      995  \n",
      "lv         977     0    0     1    0    0    0     0      978  \n",
      "nl           0   997    0     0    0    0    0     0      999  \n",
      "pl           0     0  998     0    0    0    0     0      999  \n",
      "pt           0     0    0   995    0    0    0     0      996  \n",
      "ro           0     0    0     0  927    0    0     0      928  \n",
      "sk           0     0    0     0    0  925    1     0      929  \n",
      "sl           0     0    0     0    0    0  995     0      998  \n",
      "sv           0     0    0     0    0    0    0   993      996  \n",
      "__all__    977  1000  999  1000  927  932  996  1000    20762  \n",
      "\n",
      "[22 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = ConfusionMatrix(results['language'], results['pred_lang'])\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = results[results['language'] != results['pred_lang']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 47\n"
     ]
    }
   ],
   "source": [
    "print('Number of errors:',len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return the top five languages by number of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  count\n",
       "0       cs      8\n",
       "1       fr      6\n",
       "2       da      5\n",
       "3       sk      4\n",
       "4       es      4"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.groupby('language')['pred_lang'].count().reset_index(name='count').sort_values('count',ascending=False).reset_index(drop=True).loc[:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some examples. I can only really make inferences from languages I can understand, but I think this will still capture some general problems with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def print_example(df, ind):\n",
    "    row = df.loc[ind]\n",
    "    print('True: ', row['language'], sep='')\n",
    "    print('Predicted: ', row['pred_lang'], sep='')\n",
    "    print(row['string'], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the errors contain samples of the predicted language which is obviously throwing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: cs\n",
      "Predicted: en\n",
      "jmenovali se william meyer bernard starie reginald pike thomas shaw james mcleish archibald barrowman a albert roberts a všichni budou v sobotu vyznamenáni\n"
     ]
    }
   ],
   "source": [
    "print_example(errors, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the English names are probably weighting the prediction in favour of English rather than Swiss.\n",
    "\n",
    "Similarly in this short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: de\n",
      "Predicted: en\n",
      "danke herr macartney\n"
     ]
    }
   ],
   "source": [
    "print_example(errors, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others show an obvious resemblance, containing shared (or very similar) words between the languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: fr\n",
      "Predicted: en\n",
      "la directive habitat impose un objectif explicite\n"
     ]
    }
   ],
   "source": [
    "print_example(errors, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could probably improve on these errors by using a higher-order Markov Model (involving probabilities of trigrams etc.), moving from a transition 'matrix' to a higher order tensor. This would be computationally much more expensive, but could prove to be very accurate.\n",
    "\n",
    "In the above example, such a higher order system would find that whilst the probabilties for the transitions 'un' and 'if' were probably fairly similar between French and English, the probabilties for 'un ' and 'tif' would be much higher in the former language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lstm'></a>\n",
    "## LSTM Model\n",
    "\n",
    "I'm going to try training a simple LSTM-based neural network on the language data using TensorFlow to see if I can get a similar (or even better?) accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from utils import makeDF, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array([chr(i) for i in range(2048)])\n",
    "encoder = LabelEncoder().fit(vocab)\n",
    "\n",
    "languages = next(os.walk('./txt'))[1]\n",
    "language_encoder = LabelEncoder().fit(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Let's process our data so it can be read by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_per_lang = 1000\n",
    "\n",
    "# Train data\n",
    "train = makeDF(os.getcwd(),sequences_per_lang)\n",
    "train['as_numbers'] = train['string'].apply(lambda x: encoder.transform(list(x)))\n",
    "train['length'] = train['string'].apply(lambda x: len(x))\n",
    "train['lang_as_numbers'] = language_encoder.transform(train['language'])\n",
    "\n",
    "# Test data\n",
    "test = pd.read_csv('europarl-test.txt', sep='\\t', header=None, names=['language', 'string'])\n",
    "test['string'] = test['string'].apply(lambda x: re.sub(r'[^\\u0000-\\u0800]', '', x))\n",
    "test = test[test['string'].apply(len) != 0] # remove empty strings\n",
    "test['as_numbers'] = test['string'].apply(lambda x: encoder.transform(list(x)))\n",
    "test['length'] = test['string'].apply(lambda x: len(x))\n",
    "test['lang_as_numbers'] = language_encoder.transform(test['language'])\n",
    "\n",
    "# Validation/test split\n",
    "test_len = len(test)\n",
    "rand_inds = np.random.choice(test_len,test_len)\n",
    "val = test.iloc[rand_inds[test_len//2:]]\n",
    "test = test.iloc[rand_inds[:test_len//2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10414, 5)\n",
      "Validation Shape: (10414, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Test shape: ', test.shape,'\\n', 'Validation Shape: ', val.shape, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddedDataIterator():\n",
    "    def __init__(self, df, maxlen):\n",
    "        self.df = df\n",
    "        self.maxlen = maxlen\n",
    "        self.rm_too_short()\n",
    "        self.size = len(self.df)\n",
    "        self.epochs = 0\n",
    "        self.shuffle()\n",
    "        \n",
    "    # Remove sequences with fewer items than maxlen\n",
    "    def rm_too_short(self):\n",
    "        self.df = self.df.drop(self.df[self.df['length'] < self.maxlen].index).reset_index(drop=True)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        self.cursor = 0\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        if self.cursor+n > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.loc[self.cursor:self.cursor+n-1]\n",
    "        if len(res) != n:\n",
    "            print(res)\n",
    "        self.cursor += n\n",
    "\n",
    "        # Pad sequences with 0s so they are all the same length\n",
    "        # maxlen = max(res['length'])\n",
    "        maxlen = self.maxlen\n",
    "        x = pad_sequences(res['as_numbers'].values, maxlen, padding='post', truncating='post')\n",
    "\n",
    "        return x, res['lang_as_numbers'].values, np.array([maxlen]*x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "def build_graph(\n",
    "    vocab_size = len(vocab),\n",
    "    state_size = 64,\n",
    "    batch_size = 32,\n",
    "    num_classes = len(languages),\n",
    "    learning_rate = 1e-3):\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    # Placeholders\n",
    "    x = tf.placeholder(tf.int32, shape=[batch_size, None]) # [batch_size, num_steps]\n",
    "    seqlen = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    y = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    keep_prob = tf.placeholder(tf.float32,[])\n",
    "\n",
    "    # Embedding layer\n",
    "    embeddings = tf.get_variable('embedding_matrix', shape=[vocab_size, state_size])\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # LSTM\n",
    "    lstmCell = tf.nn.rnn_cell.LSTMCell(state_size, name='basic_lstm_cell')\n",
    "    lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=keep_prob)\n",
    "    rnn_outputs, _ = tf.nn.dynamic_rnn(lstmCell, rnn_inputs, dtype=tf.float32)\n",
    "    \n",
    "    # Bidirectional LSTM - doesn't really work\n",
    "    # lstmCell_fw = tf.nn.rnn_cell.LSTMCell(state_size, name='basic_lstm_cell')\n",
    "    # lstmCell_fw = tf.contrib.rnn.DropoutWrapper(cell=lstmCell_fw, output_keep_prob=keep_prob)\n",
    "    # lstmCell_bw = tf.nn.rnn_cell.LSTMCell(state_size, name='basic_lstm_cell')\n",
    "    # lstmCell_bw = tf.contrib.rnn.DropoutWrapper(cell=lstmCell_bw, output_keep_prob=keep_prob)\n",
    "    # rnn_outputs, _ = tf.nn.bidirectional_dynamic_rnn(lstmCell_fw, lstmCell_bw, rnn_inputs, dtype=tf.float32)\n",
    "    \n",
    "    # Add dropout, as the model otherwise quickly overfits\n",
    "    # rnn_outputs = tf.nn.dropout(rnn_outputs, keep_prob)\n",
    "\n",
    "    idx = tf.range(batch_size)*tf.shape(rnn_outputs)[1] + (seqlen - 1)\n",
    "    last_rnn_output = tf.gather(tf.reshape(rnn_outputs, [-1, state_size]), idx)\n",
    "\n",
    "    # Softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(last_rnn_output, W) + b\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds,1),tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    return {\n",
    "        'x': x,\n",
    "        'seqlen': seqlen,\n",
    "        'y': y,\n",
    "        'keep_prob': keep_prob,\n",
    "        'loss': loss,\n",
    "        'ts': train_step,\n",
    "        'preds': preds,\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph(graph, batch_size = 32, num_epochs = 16, iterator = PaddedDataIterator):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        keep_prob = 0.6\n",
    "        maxlen = 64\n",
    "        tr = iterator(train, maxlen)\n",
    "        te = iterator(val, maxlen)\n",
    "        g = graph\n",
    "\n",
    "        step, accuracy = 0, 0\n",
    "        tr_losses, te_losses = [], []\n",
    "        current_epoch = 0\n",
    "        while current_epoch < num_epochs:\n",
    "            step += 1\n",
    "            batch = tr.next_batch(batch_size)\n",
    "            feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2], g['keep_prob']: keep_prob}\n",
    "            accuracy_, _ = sess.run([g['accuracy'], g['ts']], feed_dict=feed)\n",
    "            accuracy += accuracy_\n",
    "\n",
    "            if tr.epochs > current_epoch:\n",
    "                current_epoch += 1\n",
    "                tr_losses.append(accuracy / step)\n",
    "                step, accuracy = 0, 0\n",
    "\n",
    "                #eval test set\n",
    "                te_epoch = te.epochs\n",
    "                while te.epochs == te_epoch:\n",
    "                    step += 1\n",
    "                    batch = te.next_batch(batch_size)\n",
    "                    feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2], g['keep_prob']: keep_prob}\n",
    "                    accuracy_ = sess.run([g['accuracy']], feed_dict=feed)[0]\n",
    "                    accuracy += accuracy_\n",
    "\n",
    "                te_losses.append(accuracy / step)\n",
    "                step, accuracy = 0,0\n",
    "                print(\"Accuracy after epoch\", current_epoch, \" - acc:\", tr_losses[-1], \"- val_acc:\", te_losses[-1])\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        tes = iterator(test, maxlen)\n",
    "        step, accuracy = 0, 0\n",
    "        while tes.epochs == 0:\n",
    "            step += 1\n",
    "            batch = tes.next_batch(batch_size)\n",
    "            feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2], g['keep_prob']: keep_prob}\n",
    "            accuracy_ = sess.run([g['accuracy']], feed_dict=feed)[0]\n",
    "            accuracy += accuracy_\n",
    "        \n",
    "        print('\\n')\n",
    "        print('Accuracy:', accuracy/step)\n",
    "\n",
    "    return tr_losses, te_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JBremner/Envs/idiom/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 1  - acc: 0.30414438502673796 - val_acc: 0.3974014336917563\n",
      "Accuracy after epoch 2  - acc: 0.5069537533512064 - val_acc: 0.5198965827338129\n",
      "Accuracy after epoch 3  - acc: 0.646196380697051 - val_acc: 0.6616456834532374\n",
      "Accuracy after epoch 4  - acc: 0.7301441018766756 - val_acc: 0.7107688848920863\n",
      "Accuracy after epoch 5  - acc: 0.7838471849865952 - val_acc: 0.7475269784172662\n",
      "Accuracy after epoch 6  - acc: 0.8348693029490617 - val_acc: 0.7794514388489209\n",
      "Accuracy after epoch 7  - acc: 0.863103217158177 - val_acc: 0.795863309352518\n",
      "Accuracy after epoch 8  - acc: 0.8754189008042895 - val_acc: 0.7808003597122302\n",
      "Accuracy after epoch 9  - acc: 0.8877345844504021 - val_acc: 0.8068794964028777\n",
      "Accuracy after epoch 10  - acc: 0.9059148793565683 - val_acc: 0.8223920863309353\n",
      "Accuracy after epoch 11  - acc: 0.9121983914209115 - val_acc: 0.8399280575539568\n",
      "Accuracy after epoch 12  - acc: 0.9141253351206434 - val_acc: 0.8310476618705036\n",
      "Accuracy after epoch 13  - acc: 0.9193197050938338 - val_acc: 0.841726618705036\n",
      "Accuracy after epoch 14  - acc: 0.9292895442359249 - val_acc: 0.8321717625899281\n",
      "Accuracy after epoch 15  - acc: 0.9221682305630027 - val_acc: 0.8606115107913669\n",
      "Accuracy after epoch 16  - acc: 0.9313002680965148 - val_acc: 0.8594874100719424\n",
      "\n",
      "\n",
      "Accuracy: 0.8626116071428571\n"
     ]
    }
   ],
   "source": [
    "g = build_graph()\n",
    "tr_losses, te_losses = train_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86% is not bad for this problem, but I'm sure I could do better if I fine-tuned the model and trained it with a proper backend (and more training sequences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "\n",
    "## Summary\n",
    "\n",
    "Here I shall summarise the three approaches I took for this language classification problem.\n",
    "\n",
    "### N-gram Rank Similarity\n",
    "\n",
    "**Accuracy:** 80.40%\n",
    "\n",
    "> #### Pros\n",
    "> - Simple\n",
    "> - Easy to train\n",
    "\n",
    "> #### Cons\n",
    "> - Very poor for short sequences of text\n",
    "\n",
    "> #### Improvements\n",
    "> - Larger training dataset\n",
    "\n",
    "### Markov Chain MLE\n",
    "\n",
    "**Accuracy:** 99.77%\n",
    "\n",
    "> #### Pros\n",
    "> - The best performing model\n",
    "\n",
    "\n",
    "> #### Cons\n",
    "> - A little more expensive to evaluate for longer strings\n",
    "> - Smoothing transition matrices difficult\n",
    "\n",
    "> #### Improvements\n",
    "> - Implement _Kneser-Ney_ smoothing\n",
    "> - Higher-order Markov Model\n",
    "> - Larger training dataset\n",
    "\n",
    "### LSTM\n",
    "\n",
    "**Accuracy:** 86.26%\n",
    "\n",
    "> #### Pros\n",
    "> - Straightforward to evaluate\n",
    "\n",
    "> #### Cons\n",
    "> - Complex\n",
    "> - Difficult to train\n",
    "> - Takes fixed string input length\n",
    "\n",
    "> #### Improvements\n",
    "> - Larger training dataset (with a better backend)\n",
    "> - Fine-tune model parameters\n",
    "> - Try more sophisticated implementations (more layers, bidirectional etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
